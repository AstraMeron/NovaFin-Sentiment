{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dce6d946",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Mer\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- News Data Sentiment Analysis Complete ---\n",
      "Sentiment Score calculated for 55987 headlines.\n",
      "                                            headline  sentiment_score  \\\n",
      "0            Stocks That Hit 52-Week Highs On Friday            0.000   \n",
      "1         Stocks That Hit 52-Week Highs On Wednesday            0.000   \n",
      "2                      71 Biggest Movers From Friday            0.000   \n",
      "3       46 Stocks Moving In Friday's Mid-Day Session            0.000   \n",
      "4  B of A Securities Maintains Neutral on Agilent...            0.296   \n",
      "\n",
      "         Date stock  \n",
      "0  2020-06-05     A  \n",
      "1  2020-06-03     A  \n",
      "2  2020-05-26     A  \n",
      "3  2020-05-22     A  \n",
      "4  2020-05-22     A  \n",
      "Loaded AAPL and calculated Daily_Return. Shape: (3740, 11)\n",
      "Loaded AMZN and calculated Daily_Return. Shape: (3740, 11)\n",
      "Loaded GOOG and calculated Daily_Return. Shape: (3740, 11)\n",
      "Loaded META and calculated Daily_Return. Shape: (2889, 11)\n",
      "Loaded MSFT and calculated Daily_Return. Shape: (3740, 11)\n",
      "Loaded NVDA and calculated Daily_Return. Shape: (3740, 11)\n",
      "--- Stock Data Loading and Daily Returns Calculation Complete ---\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Load Data, Sentiment Analysis, and Calculate Daily Returns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import os\n",
    "\n",
    "# --- 1. Load News Data and Prepare for Sentiment Analysis (Task 3 Requirement) ---\n",
    "\n",
    "NEWS_FILE_PATH = '../data/newsData/raw_analyst_ratings.csv'\n",
    "df_news = pd.read_csv(NEWS_FILE_PATH)\n",
    "\n",
    "# Robust Date Cleaning (FIXED: Handling mixed timezone awareness)\n",
    "df_news['date'] = pd.to_datetime(df_news['date'], errors='coerce')\n",
    "df_news.dropna(subset=['date'], inplace=True)\n",
    "\n",
    "# Check for timezone-awareness before localizing\n",
    "if df_news['date'].dt.tz is None:\n",
    "    # If the column is naive, localize it to the original timezone (UTC-4)\n",
    "    df_news['date'] = df_news['date'].dt.tz_localize('America/New_York', ambiguous='infer')\n",
    "\n",
    "# Now that the column is timezone-aware, convert it to the target UTC timezone\n",
    "df_news['date'] = df_news['date'].dt.tz_convert('UTC')\n",
    "\n",
    "# Create a normalized date column (only date, no time) for merging\n",
    "df_news['Date'] = df_news['date'].dt.normalize().dt.date\n",
    "\n",
    "\n",
    "# Initialize VADER sentiment analyzer (part of nltk)\n",
    "try:\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "except LookupError:\n",
    "    nltk.download('vader_lexicon')\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_vader_sentiment(headline):\n",
    "    \"\"\"Calculates the compound sentiment score for a given headline.\"\"\"\n",
    "    if pd.isna(headline):\n",
    "        return 0\n",
    "    # Use the compound score as the final sentiment metric\n",
    "    return sia.polarity_scores(headline)['compound']\n",
    "\n",
    "# Apply sentiment analysis (This is a long-running step!)\n",
    "df_news['sentiment_score'] = df_news['headline'].apply(get_vader_sentiment)\n",
    "\n",
    "print(\"--- News Data Sentiment Analysis Complete ---\")\n",
    "print(f\"Sentiment Score calculated for {len(df_news)} headlines.\")\n",
    "print(df_news[['headline', 'sentiment_score', 'Date', 'stock']].head())\n",
    "\n",
    "\n",
    "# --- 2. Load Processed Stock Data and Calculate Daily Returns (Task 3 Requirement) ---\n",
    "\n",
    "TICKERS = ['AAPL', 'AMZN', 'GOOG', 'META', 'MSFT', 'NVDA']\n",
    "STOCK_DATA_DIR = '../data/yfinance_data/'\n",
    "df_stocks = {}\n",
    "\n",
    "for ticker in TICKERS:\n",
    "    processed_file = f'processed_{ticker}_data.csv'\n",
    "    processed_path = os.path.join(STOCK_DATA_DIR, processed_file)\n",
    "    \n",
    "    if os.path.exists(processed_path):\n",
    "        # Load the processed data which already has TA indicators\n",
    "        df = pd.read_csv(processed_path, index_col='Date', parse_dates=True)\n",
    "        \n",
    "        # Calculate Daily Stock Returns (Percentage Change) [cite: 154]\n",
    "        df['Daily_Return'] = df['Close'].pct_change() * 100\n",
    "        \n",
    "        # Drop the first row (which now contains NaN return)\n",
    "        df.dropna(subset=['Daily_Return'], inplace=True)\n",
    "        \n",
    "        df_stocks[ticker] = df\n",
    "        print(f\"Loaded {ticker} and calculated Daily_Return. Shape: {df.shape}\")\n",
    "    else:\n",
    "        print(f\"Warning: Processed file not found for {ticker} at {processed_path}\")\n",
    "\n",
    "print(\"--- Stock Data Loading and Daily Returns Calculation Complete ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30594fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Daily Sentiment Aggregation Complete ---\n",
      "  stock        Date  Avg_Sentiment\n",
      "0     A  2020-05-22         0.0480\n",
      "1     A  2020-05-26         0.0000\n",
      "2     A  2020-06-03         0.0000\n",
      "3     A  2020-06-05         0.0000\n",
      "4    AA  2020-05-18         0.8519\n",
      "\n",
      "--- Final Correlation Analysis: Sentiment vs. Daily Return ---\n",
      "Pearson Correlation Coefficient (Avg Daily Sentiment vs. Daily % Return)\n",
      "        Correlation_Coefficient  Data_Points_Merged\n",
      "Ticker                                             \n",
      "AAPL                     1.0000                   2\n",
      "NVDA                     0.5227                   4\n",
      "GOOG                    -0.2344                   5\n",
      "AMZN                    -1.0000                   2\n",
      "META                        NaN                   0\n",
      "MSFT                        NaN                   0\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Sentiment Aggregation, Data Merging, and Correlation Analysis\n",
    "\n",
    "# --- 1. Aggregate News Sentiment by Day and Ticker (Task 3 Requirement) ---\n",
    "\n",
    "# Group the news articles by the stock ticker and the publication date (normalized)\n",
    "# Then calculate the mean of the sentiment scores.\n",
    "df_daily_sentiment = df_news.groupby(['stock', 'Date'])['sentiment_score'].mean().reset_index()\n",
    "df_daily_sentiment.rename(columns={'sentiment_score': 'Avg_Sentiment'}, inplace=True)\n",
    "\n",
    "print(\"--- Daily Sentiment Aggregation Complete ---\")\n",
    "print(df_daily_sentiment.head())\n",
    "\n",
    "\n",
    "# --- 2. Perform Merging and Correlation Analysis (Task 3 Requirement) ---\n",
    "\n",
    "TICKERS = ['AAPL', 'AMZN', 'GOOG', 'META', 'MSFT', 'NVDA']\n",
    "correlation_results = {}\n",
    "\n",
    "for ticker in TICKERS:\n",
    "    # 2a. Get the Daily Returns data (from Cell 1)\n",
    "    df_stock = df_stocks.get(ticker)\n",
    "    \n",
    "    # 2b. Filter the aggregated sentiment data for the current ticker\n",
    "    df_sentiment_ticker = df_daily_sentiment[df_daily_sentiment['stock'] == ticker].copy()\n",
    "    \n",
    "    # Ensure the 'Date' column in the sentiment data is ready for merge (convert date object to datetime)\n",
    "    df_sentiment_ticker['Date'] = pd.to_datetime(df_sentiment_ticker['Date'])\n",
    "    df_sentiment_ticker.set_index('Date', inplace=True)\n",
    "    \n",
    "    if df_stock is not None and not df_sentiment_ticker.empty:\n",
    "        # 2c. Merge the sentiment with the stock data on the 'Date' index\n",
    "        # We use an inner join to only keep dates where both news and returns exist\n",
    "        df_merged = df_stock.merge(\n",
    "            df_sentiment_ticker[['Avg_Sentiment']], \n",
    "            left_index=True, \n",
    "            right_index=True, \n",
    "            how='inner'\n",
    "        )\n",
    "        \n",
    "        # 2d. Calculate Pearson Correlation Coefficient\n",
    "        # Calculate the correlation between the averaged sentiment and the daily stock return\n",
    "        correlation = df_merged['Avg_Sentiment'].corr(df_merged['Daily_Return'])\n",
    "        \n",
    "        correlation_results[ticker] = {\n",
    "            'Correlation_Coefficient': correlation,\n",
    "            'Data_Points_Merged': len(df_merged)\n",
    "        }\n",
    "    else:\n",
    "        correlation_results[ticker] = {\n",
    "            'Correlation_Coefficient': np.nan,\n",
    "            'Data_Points_Merged': 0\n",
    "        }\n",
    "\n",
    "\n",
    "# --- 3. Present Final Results ---\n",
    "df_correlation = pd.DataFrame.from_dict(correlation_results, orient='index')\n",
    "df_correlation.index.name = 'Ticker'\n",
    "df_correlation['Correlation_Coefficient'] = df_correlation['Correlation_Coefficient'].round(4)\n",
    "df_correlation.sort_values(by='Correlation_Coefficient', ascending=False, inplace=True)\n",
    "\n",
    "print(\"\\n--- Final Correlation Analysis: Sentiment vs. Daily Return ---\")\n",
    "print(\"Pearson Correlation Coefficient (Avg Daily Sentiment vs. Daily % Return)\")\n",
    "print(df_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b16230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
